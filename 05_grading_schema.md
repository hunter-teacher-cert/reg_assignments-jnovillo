## Grading schema

Lab: csv_lab.py

https://github.com/hunter-teacher-cert/spring-2021-methods-2/blob/main/resources/csv_lab.py

https://github.com/hunter-teacher-cert/spring-2021-methods-2/blob/main/resources/csv_lab_solved.py

For this lab, I would like to design a grading schema based on three evaluation levels: Strong (3), Average (2), and Weak (1). The criteria that I would evaluate are:

**Content:** It is essential to assess how well the students assimilate the content. In this case, I would like to evaluate the studentsâ€™ knowledge on reading CSV files, creating functions, working with lists, dictionaries, conditions, and loops in Python.

**Functionality:** This criterion is also important because the code developed by the students should give the desired results. Students should show their problem-solving skills by applying their knowledge in practical exercises.

**Efficiency:** This criterion evaluates the programming skills of the students. It reflects how well students write code making good decisions to make it short, clean, and easy to read. Students should avoid code redundancy.

**Documentation:** Students should get used to documenting their code. Describing their code will make it easy to read for others and benefit them because it can help them remember what they did.

This is the rubric I would use for this case:

| **Criteria**      | **Strong (3)**    |  **Average (2)**  | **Weak (1)**      |
| ------------- | ------------- | ------------- | ------------- |
| **Content**  | Student shows an understanding of the content: reading CSV files, creating functions, working with lists, dictionaries, conditions, and loops. |  Student shows some understanding of the content: reading CSV files, creating functions, working with lists, dictionaries, conditions, and loops. | Student does not show understanding of the content: reading CSV files, creating functions, working with lists, dictionaries, conditions, and loops.  | 
| **Functionality**  | Code generates expected output. | Code partially generates expected output.  | Code does not work or does not generate expected output.  |
| **Efficiency**   | Code is clean and easy to read.  | Code is mostly clean and easy to read.   | Code is long, not organized, and difficult to read.  |
| **Documentation**  | Code is well-documented.  | Code is partially documented.  | Code is not documented.  |
